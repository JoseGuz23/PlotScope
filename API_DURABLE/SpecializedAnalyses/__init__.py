# =============================================================================
# SpecializedAnalyses/__init__.py - SYLPHRENA 4.2 (GEMINI + CLAUDE FALLBACK)
# =============================================================================
import logging
import json
import os
import re
from google import genai
from google.genai import types
import anthropic

logging.basicConfig(level=logging.INFO)

# =============================================================================
# CONFIGURACI√ìN
# =============================================================================
GEMINI_MODEL_FAST = 'gemini-2.5-flash'
GEMINI_MODEL_SMART = 'gemini-3-pro-preview' # O 'gemini-3-pro-preview' si tienes acceso
CLAUDE_MODEL = 'claude-sonnet-4-20250514'

PROMPTS = {
    "cliches": """Eres un editor literario experto. Analiza este texto buscando patrones ling√º√≠sticos repetitivos, muletillas y clich√©s.
    Responde SOLO con este JSON: {"patrones_repetidos": [{"patron": "string", "frecuencia": 0}], "cliches_detectados": ["string"]}""",
    
    "dialogue": """Eres un experto en narrativa. Analiza las voces de los personajes. ¬øSon distinguibles?
    Responde SOLO con este JSON: {"voces_distintivas": true, "score_diferenciacion": 0, "analisis_por_personaje": [{"nombre": "string", "rasgos_voz": "string"}]}""",
    
    "economy": """Eval√∫a la econom√≠a narrativa. ¬øEl texto es eficiente o tiene "grasa"?
    Responde SOLO con este JSON: {"score_eficiencia": 0, "capitulos_baja_densidad": ["string"], "sugerencias": ["string"]}""",
    
    # CORRECCI√ìN AQU√ç: Doble llave {{ }} para el JSON, llave simple { } para la variable
    "genre": """Compara la estructura de este texto con las convenciones del g√©nero {genre}.
    Responde SOLO con este JSON: {{"cumplimiento_genero": 0, "elementos_ausentes": ["string"], "subversiones_intencionales": ["string"]}}"""
}

def clean_json_text(text):
    """Limpia el texto para extraer solo el JSON v√°lido."""
    if not text: return "{}"
    # Eliminar bloques markdown
    text = re.sub(r'^```json\s*', '', text, flags=re.MULTILINE)
    text = re.sub(r'^```\s*', '', text, flags=re.MULTILINE)
    text = re.sub(r'```$', '', text, flags=re.MULTILINE)
    # Intentar encontrar el primer { y el √∫ltimo }
    start = text.find('{')
    end = text.rfind('}')
    if start != -1 and end != -1:
        text = text[start:end+1]
    return text.strip()

def call_claude_fallback(prompt, analysis_name):
    """Intenta realizar el an√°lisis con Claude si Gemini falla."""
    try:
        api_key = os.environ.get("ANTHROPIC_API_KEY")
        if not api_key:
            logging.warning("‚ö†Ô∏è No hay ANTHROPIC_API_KEY para fallback.")
            return None

        logging.info(f"üõ°Ô∏è Activando Claude Fallback para: {analysis_name}")
        client = anthropic.Anthropic(api_key=api_key)
        
        message = client.messages.create(
            model=CLAUDE_MODEL,
            max_tokens=4096,
            temperature=0.3,
            messages=[{"role": "user", "content": prompt}]
        )
        
        response_text = message.content[0].text
        return json.loads(clean_json_text(response_text))
        
    except Exception as e:
        logging.error(f"‚ùå Claude Fallback fall√≥ para {analysis_name}: {e}")
        return None

def safe_analyze(gemini_client, model, prompt, analysis_name):
    """Ejecuta an√°lisis con estrategia: Gemini -> Fallback Claude -> Error Controlado."""
    
    # 1. INTENTO CON GEMINI
    try:
        response = gemini_client.models.generate_content(
            model=model,
            contents=prompt,
            config=types.GenerateContentConfig(
                response_mime_type="application/json",
                temperature=0.3
            )
        )
        
        if response.text:
            return json.loads(clean_json_text(response.text))
        else:
            logging.warning(f"‚ö†Ô∏è Gemini devolvi√≥ respuesta vac√≠a para {analysis_name} (Posible filtro de seguridad).")
            
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è Error en Gemini para {analysis_name}: {e}")

    # 2. FALLBACK A CLAUDE (Si Gemini fall√≥ o devolvi√≥ vac√≠o)
    claude_result = call_claude_fallback(prompt, analysis_name)
    if claude_result:
        return claude_result

    # 3. SI TODO FALLA, RETORNAR ESTRUCTURA VAC√çA (NO CRASHEAR)
    logging.error(f"‚ùå Fallaron todos los intentos para {analysis_name}")
    return {
        "error": "Analysis failed on all providers",
        "status": "failed"
    }

def main(payload) -> str:
    try:
        # Preparaci√≥n de datos
        if isinstance(payload, str):
            data = json.loads(payload)
        else:
            data = payload
            
        bible = data.get('bible', {})
        # Contexto del libro (primeras 10k palabras para no saturar)
        # Nota: Para an√°lisis profundos, idealmente se pasa el texto, 
        # pero aqu√≠ usamos la Biblia como proxy contextual si no hay texto completo.
        # Si tienes el texto completo disponible en payload, √∫salo.
        
        genre = data.get('book_metadata', {}).get('genre') or \
                bible.get('identidad_obra', {}).get('genero', 'Ficci√≥n General')
        
        logging.info(f"üî¨ Iniciando an√°lisis especializados. G√©nero: {genre}")
        
        gemini_key = os.environ.get('GEMINI_API_KEY')
        if not gemini_key:
            return json.dumps({"error": "No Gemini API Key"})
            
        client = genai.Client(api_key=gemini_key)
        results = {}

        # Agregar contexto al prompt (Breve resumen de la obra para que la IA sepa de qu√© habla)
        sinopsis = bible.get('identidad_obra', {}).get('contrato_con_lector', '')
        context_prompt = f"\nCONTEXTO DE LA OBRA:\nG√©nero: {genre}\nSinopsis: {sinopsis}\n\n"

        # --- EJECUCI√ìN SECUENCIAL BLINDADA ---
        
        # 1. Clich√©s
        results['cliches_analysis'] = safe_analyze(
            client, GEMINI_MODEL_FAST, context_prompt + PROMPTS['cliches'], 'cliches'
        )

        # 2. Di√°logo
        results['dialogue_analysis'] = safe_analyze(
            client, GEMINI_MODEL_SMART, context_prompt + PROMPTS['dialogue'], 'dialogue'
        )

        # 3. Econom√≠a
        results['narrative_economy'] = safe_analyze(
            client, GEMINI_MODEL_FAST, context_prompt + PROMPTS['economy'], 'economy'
        )

        # 4. Comparativa de G√©nero (Aqu√≠ sol√≠a fallar)
        formatted_prompt = context_prompt + PROMPTS['genre'].format(genre=genre)
        results['genre_comparison'] = safe_analyze(
            client, GEMINI_MODEL_SMART, formatted_prompt, 'genre'
        )

        return json.dumps({
            "status": "success",
            "specialized_analyses": results
        })

    except Exception as e:
        logging.error(f"‚ùå Error fatal en SpecializedAnalyses wrapper: {str(e)}")
        return json.dumps({"status": "error", "error": str(e)})