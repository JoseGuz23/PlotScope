# =============================================================================
# SegmentBook/__init__.py - SYLPHRENA 4.0
# =============================================================================
# CAMBIOS DESDE 3.1:
#   - Genera metadatos jer√°rquicos completos (parent_chapter_id, fragment_index, etc.)
#   - Preserva relaci√≥n fragmento-cap√≠tulo durante todo el pipeline
#   - Resuelve el Problema Cr√≠tico 1: P√©rdida de Contexto Jer√°rquico
# =============================================================================

import azure.functions as func
import regex as re
import json
import logging
import os
import pdfplumber
from docx import Document

MAX_CHARS_PER_CHUNK = 12000

logging.basicConfig(level=logging.INFO)


def extract_text_from_file(file_path: str) -> str:
    """Extrae texto de PDF, DOCX o TXT."""
    extension = os.path.splitext(file_path)[1].lower()
    
    logging.info(f"üìÇ Extrayendo texto de: {file_path} (formato: {extension})")
    
    if extension == '.pdf':
        text = ""
        with pdfplumber.open(file_path) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
        return text
    
    elif extension == '.docx':
        doc = Document(file_path)
        return "\n".join([para.text for para in doc.paragraphs])
    
    elif extension == '.txt':
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    
    else:
        raise ValueError(f"Formato no soportado: {extension}. Use .pdf, .docx o .txt")


def smart_split(text: str, max_chars: int) -> list:
    """
    Divide un texto largo en fragmentos m√°s peque√±os respetando los saltos de l√≠nea.
    Intenta cortar en p√°rrafos completos cuando es posible.
    """
    if len(text) <= max_chars:
        return [text]
    
    chunks = []
    remaining_text = text
    
    while len(remaining_text) > max_chars:
        # Buscar punto de corte ideal (doble salto de l√≠nea = fin de p√°rrafo)
        split_point = remaining_text.rfind('\n\n', 0, max_chars)
        
        # Si no hay doble salto, buscar salto simple
        if split_point == -1 or split_point < max_chars // 2:
            split_point = remaining_text.rfind('\n', 0, max_chars)
        
        # Si tampoco hay salto de l√≠nea, cortar en punto o espacio
        if split_point == -1 or split_point < max_chars // 2:
            split_point = remaining_text.rfind('. ', 0, max_chars)
            if split_point != -1:
                split_point += 1  # Incluir el punto
        
        # √öltimo recurso: cortar en el l√≠mite
        if split_point == -1 or split_point < max_chars // 2:
            split_point = max_chars
        
        chunk = remaining_text[:split_point].strip()
        if chunk:
            chunks.append(chunk)
        remaining_text = remaining_text[split_point:].strip()
    
    if remaining_text:
        chunks.append(remaining_text)
    
    return chunks


def detect_section_type(title_line: str) -> str:
    """
    Normaliza el tipo de secci√≥n basado en el t√≠tulo detectado.
    Permite que la l√≥gica posterior trate 'III.' igual que 'Cap√≠tulo 3'.
    """
    title_lower = title_line.lower().strip()
    
    # 1. Grupo ACTO/PARTE (Nivel Alto)
    if re.match(r'^(acto|parte)\b', title_lower):
        return 'ACT'
    
    # 2. Palabras Clave Especiales
    if re.match(r'^(pr√≥logo|prefacio|introducci√≥n)', title_lower):
        return 'PROLOGUE'
    if re.match(r'^interludio', title_lower):
        return 'INTERLUDE'
    if re.match(r'^(ep√≠logo|nota)', title_lower):
        return 'EPILOGUE'
    
    # Casos especiales de inicio sin t√≠tulo formal
    if "inicio" in title_lower and "contexto" in title_lower:
        return 'CONTEXT'

    # 3. Todo lo dem√°s se considera CAP√çTULO
    return 'CHAPTER'


def generate_hierarchical_metadata(chapters_raw: list) -> list:
    """
    NUEVA FUNCI√ìN 4.0: Genera metadatos jer√°rquicos completos.
    
    Cada fragmento incluye:
    - id: Identificador √∫nico global del fragmento
    - parent_chapter_id: ID del cap√≠tulo padre
    - original_title: T√≠tulo limpio del cap√≠tulo
    - title: T√≠tulo de display (incluye info de fragmentaci√≥n)
    - fragment_index: Posici√≥n del fragmento dentro del cap√≠tulo (1-based)
    - total_fragments: Total de fragmentos del cap√≠tulo
    - section_type: Tipo de secci√≥n (CHAPTER, PROLOGUE, etc.)
    - is_first_fragment: Bandera booleana
    - is_last_fragment: Bandera booleana
    - content: Texto del fragmento
    - word_count: Conteo de palabras
    """
    
    final_list = []
    global_fragment_id = 1
    chapter_id = 1
    
    for chapter_data in chapters_raw:
        raw_title = chapter_data['title']
        content = chapter_data['content']
        section_type = chapter_data['section_type']
        
        # Decidir si fragmentar
        if len(content) > MAX_CHARS_PER_CHUNK:
            logging.warning(f"‚ö†Ô∏è Fragmentando cap√≠tulo extenso: '{raw_title}' ({len(content)} chars)")
            sub_chunks = smart_split(content, MAX_CHARS_PER_CHUNK)
            total_fragments = len(sub_chunks)
            
            for idx, chunk in enumerate(sub_chunks):
                fragment_index = idx + 1
                is_first = (fragment_index == 1)
                is_last = (fragment_index == total_fragments)
                
                fragment_obj = {
                    'id': global_fragment_id,
                    'parent_chapter_id': chapter_id,
                    'original_title': raw_title,
                    'title': f"{raw_title} (Fragmento {fragment_index}/{total_fragments})",
                    'fragment_index': fragment_index,
                    'total_fragments': total_fragments,
                    'section_type': section_type,
                    'is_first_fragment': is_first,
                    'is_last_fragment': is_last,
                    'is_fragment': True,
                    'content': chunk,
                    'word_count': len(chunk.split())
                }
                
                final_list.append(fragment_obj)
                global_fragment_id += 1
        else:
            # Cap√≠tulo at√≥mico (no requiere fragmentaci√≥n)
            fragment_obj = {
                'id': global_fragment_id,
                'parent_chapter_id': chapter_id,
                'original_title': raw_title,
                'title': raw_title,
                'fragment_index': 1,
                'total_fragments': 1,
                'section_type': section_type,
                'is_first_fragment': True,
                'is_last_fragment': True,
                'is_fragment': False,
                'content': content,
                'word_count': len(content.split())
            }
            
            final_list.append(fragment_obj)
            global_fragment_id += 1
        
        chapter_id += 1
    
    return final_list


def main(book_path: str) -> dict:
    """
    Funci√≥n principal que segmenta un libro en cap√≠tulos con metadatos jer√°rquicos.
    
    Args:
        book_path: Ruta al archivo del libro (.pdf, .docx, o .txt)
    
    Returns:
        Diccionario con:
        - fragments: Lista de fragmentos con metadatos jer√°rquicos completos
        - book_metadata: Informaci√≥n global del libro
        - chapter_map: Mapa de cap√≠tulos para referencia r√°pida
    """
    try:
        # ============================================
        # FASE 1: EXTRAER TEXTO DEL ARCHIVO
        # ============================================
        sample_text = extract_text_from_file(book_path)
        
        logging.info(f"üìñ Texto extra√≠do: {len(sample_text)} caracteres")
        
        if len(sample_text.strip()) < 100:
            raise ValueError("El archivo parece estar vac√≠o o tiene muy poco contenido")

        # ============================================
        # FASE 2: DEFINICI√ìN DE PATRONES (REGEX)
        # ============================================
        
        # GRUPO A: Narrativa Especial
        special_keywords = r'(?:Pr√≥logo|Prefacio|Introducci√≥n|Interludio|Ep√≠logo|Nota para el editor)'

        # GRUPO B: Estructura Mayor
        acts_and_parts = r'(?:Acto|Parte)\s+(?:\d+|[IVXLCDM]+)'

        # GRUPO C: Cap√≠tulos y Variaciones
        chapter_variations = r'(?:Cap√≠tulo\s+(?:\d+|[IVXLCDM]+)|Final|\b[IVXLCDM]+\.|\b\d+\.)'

        # REGEX MAESTRO
        full_pattern = f'(?mi)(?:^\\s*)(?:{special_keywords}|{acts_and_parts}|{chapter_variations})[^\n]*'
        
        logging.info("üîç Iniciando segmentaci√≥n con metadatos jer√°rquicos...")

        # ============================================
        # FASE 3: DETECCI√ìN DE CAP√çTULOS
        # ============================================
        original_chapters = re.split(f'(?={full_pattern})', sample_text)
        
        chapters_raw = []

        for i, raw_chapter in enumerate(original_chapters):
            if not raw_chapter.strip():
                continue

            lines = raw_chapter.strip().split('\n')
            raw_title = lines[0].strip()
            
            # L√≥gica para detectar si el primer fragmento es el "Inicio" sin t√≠tulo
            if i == 0 and not re.match(full_pattern, raw_title):
                raw_title = "Inicio / Contexto"

            section_type = detect_section_type(raw_title)
            content = '\n'.join(lines[1:]) if len(lines) > 1 else ""
            
            # Si es el primer bloque y no tiene contenido separado
            if i == 0 and content == "":
                content = raw_chapter
                raw_title = "Inicio / Contexto"

            # Filtro de contenido muy corto
            if len(content.split()) < 20:
                continue

            chapters_raw.append({
                'title': raw_title,
                'content': content,
                'section_type': section_type
            })

        # ============================================
        # FASE 4: GENERAR METADATOS JER√ÅRQUICOS
        # ============================================
        fragments = generate_hierarchical_metadata(chapters_raw)
        
        # ============================================
        # FASE 5: GENERAR MAPA DE CAP√çTULOS
        # ============================================
        chapter_map = {}
        for frag in fragments:
            parent_id = frag['parent_chapter_id']
            if parent_id not in chapter_map:
                chapter_map[parent_id] = {
                    'original_title': frag['original_title'],
                    'section_type': frag['section_type'],
                    'fragment_ids': [],
                    'total_fragments': frag['total_fragments']
                }
            chapter_map[parent_id]['fragment_ids'].append(frag['id'])
        
        # ============================================
        # FASE 6: METADATOS GLOBALES DEL LIBRO
        # ============================================
        total_words = sum(f['word_count'] for f in fragments)
        total_chapters = len(chapter_map)
        total_fragments = len(fragments)
        
        book_metadata = {
            'total_words': total_words,
            'total_chapters': total_chapters,
            'total_fragments': total_fragments,
            'source_file': book_path,
            'fragmentation_threshold': MAX_CHARS_PER_CHUNK
        }
        
        # Log de resultados
        logging.info(f"‚úÖ Segmentaci√≥n completada:")
        logging.info(f"   üìö Cap√≠tulos: {total_chapters}")
        logging.info(f"   üìÑ Fragmentos: {total_fragments}")
        logging.info(f"   üìù Palabras totales: {total_words:,}")
        
        for frag in fragments[:5]:  # Log primeros 5
            logging.info(f"   ID: {frag['id']} | [{frag['section_type']}] {frag['title']} | Palabras: {frag['word_count']}")
        
        if total_fragments > 5:
            logging.info(f"   ... y {total_fragments - 5} fragmentos m√°s")

        return {
            'fragments': fragments,
            'book_metadata': book_metadata,
            'chapter_map': chapter_map
        }
        
    except Exception as e:
        logging.error(f"‚ùå Error en SegmentBook: {str(e)}")
        raise e
